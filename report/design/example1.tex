\chapter{System identification}
\label{identification_design}

\emph{In this chapter, the Multi-inlet, Multi-WT model, which has been derived based on first principles in \chapref{system_modelling}, is reformulated such that it is suitable for system identification. First, the structure of the model is discussed, then a Neural Network(NN) based identification method is presented. In the first case, the identification is carried out on a simple example, then on the Randers WSS EPANET model. In the second case, the identification is carried out based on measurements from the real-world network.}

\section{Model structure of the Multi-inlet, Multi-WT system}
\label{model_structure_of_the_multi_inlet_multi_WT_system}

In \chapref{system_modelling}, the model of a multi-inlet WSS with the extension of multiple WTs has been derived. The presented model has been given by a non-linear SS representation, which consists of the equations describing the dynamics, the outputs and the constraints on the network. As the model derivation is based on first principles, some insight into the structure and the input-output relation is available. 

\subsection{Output equation}
\label{output_eq_identification}

The model needs to be identified in order to utilize it for control purposes. Therefore let us recall the governing equations. The output vector $\bar{p}_{\mathcal{K}}$ of the inlet pressures is given in discrete form such that

\begin{equation}
  \label{recall_output_eq}
  \bar{p}_{\mathcal{K},k} = K^T \bar{H}^{-T}_{\mathcal{T}}f_{\mathcal{T}}(A_2 q_{\mathcal{C},k} + A_3 K \bar{d}_{\mathcal{K},k} - A_3 D v_{\mathcal{D}} \sigma_k) - K^T\bar{H}^{-T}_{\mathcal{T}}\hat{H}^{T}_{\mathcal{T}} (\hat{p}_k + \hat{h}) - K^T\bar{h} ,
\end{equation} 

\begin{minipage}[t]{0.4\textwidth}
where\\
\hspace*{8mm} $A_2 = -\bar{H}^{-1}_{\mathcal{T}} \bar{H}_{\mathcal{C}} $, \vspace*{1.5mm}\\
\hspace*{8mm} $A_3 = \bar{H}^{-1}_{\mathcal{T}}$.
\end{minipage}

and furthermore, $\bar{d}_{\mathcal{K},k}$ inlet flows, $\sigma_k$ total demand, $v_{\mathcal{D}}$ distribution parameter, $q_{\mathcal{C},k}$ flows in set $\mathcal{C}$, $\hat{p}_k$ pressures in the WTs, $\hat{h}$ elevations of the WTs and $K^T\bar{h} = \bar{h}_{\mathcal{K}} $ the elevations of the pumping stations. The corresponding values of the pressures and flows in the network are evaluated at each time step $k$. 

Additionally, let us recall the constraint on $q_\mathcal{C}$, and rewrite it in discrete-time form such that

 \begin{equation}
\label{recall_constraint eq}
f_{\mathcal{C}}(q_{\mathcal{C},k}) - A_1(\hat{p}_k + \hat{h}) + A_2^T f_{\mathcal{T}}(A_2 q_{\mathcal{C},k} + A_3 K \bar{d}_{\mathcal{K},k} - A_3 D v_{\mathcal{D}} \sigma_k) = 0.
\end{equation} 

It is important to point out that the model in \chapref{system_modelling} has been derived in a general manner, taking into account that $v_{\mathcal{D}}$ is a time-varying distribution parameter of the demands. However, in the further description, let us restrict ourselves and assume that $v_{\mathcal{D}}$ is constant.  From the technical point of view, the identification becomes less complex, as in this case $v_{\mathcal{D}}$ is a linear constant parameter. Furthermore, there is no need to introduce $v_{\mathcal{D}}$ as a time-varying parameter on the EPANET data, however on the real measurement data, the possible demand variations might be experienced. In \eqref{recall_constraint eq} and \eqref{recall_output_eq} the assumption of $v_{\mathcal{D}}$ being constant is already taken into account, therefore $v_{\mathcal{D}}$ does not have any time index.

% This assumption is beneficial from the system point of view, as the total consumption $\sigma_k$ can be represented simply by the sum of the hourly demand variations $1^T \bar{d}_{\mathcal{D}}$. 

The constraint on $q_\mathcal{C}$ in \eqref{recall_constraint eq} is given by an implicit expression for which an analytical soulution has not been derived. The explicit solution for the constraint has a structure like \eqref{qc_abstraction}, however we do not know how it looks exactly.

 \begin{equation}
\label{qc_abstraction}
q_{\mathcal{C},k} = q_\mathcal{C} \big( (\hat{p}_k + \hat{h}),\bar{d}_{\mathcal{K},k}, \sigma_k\big).
\end{equation} 

It is shown in \eqref{qc_abstraction} that the $q_\mathcal{C}$ flows in the network depend on the same physical measures, i.e. the same variables as the outputs $\bar{p}_{\mathcal{K}}$. By substituting \eqref{qc_abstraction} into \eqref{recall_output_eq}, we get the following output equation

\vspace{-4mm}
\begin{align}
  \label{recall_output_eq_2}
      \bar{p}_{\mathcal{K},k}  = & \nonumber K^T \bar{H}^{-T}_{\mathcal{T}}f_{\mathcal{T}} \big (A_2 q_{\mathcal{C}}\big ((\hat{p}_k + \hat{h}),\bar{d}_{\mathcal{K},k}, \sigma_k \big) + A_3 K \bar{d}_{\mathcal{K},k} - A_3 D v_{\mathcal{D}} \sigma_k \big)   \\ &  - K^T\bar{H}^{-T}_{\mathcal{T}}\hat{H}^{T}_{\mathcal{T}} (\hat{p}_k + \hat{h}) - \bar{h}_{\mathcal{K}} .
\end{align}

\vspace{-4mm}
In \eqref{recall_output_eq_2}, the pressure head in the pumping stations $\bar{p}_{\mathcal{K},k}$ is given by the expression on the right-hand side. Let us write \eqref{recall_output_eq_2} in a form where the non-linear expression on the right-hand side is replaced with a non-linear function $\tilde{f}_1(\cdot)$, which has an unknown structure but has the same variables in the argument. Thus, a reformulated output equation can be given such that 

 \begin{equation}
  \label{recall_output_eq_3}
     \bar{p}_{\mathcal{K},k}  = \tilde{f}_1 \big((\hat{p}_k + \hat{h}),\bar{d}_{\mathcal{K},k}, \sigma_k\big) + \tilde{a}_1 (\hat{p}_k + \hat{h}) - \bar{h}_{\mathcal{K}}, 
\end{equation} 

The output equation described in \eqref{recall_output_eq_3} is a mapping defined by the non-linear function $\tilde{f}_1$ and the linear term, which maps the input set, $u_k = ( \hat{p}_k+\hat{h} \ \bar{d}_{\mathcal{K},k} \ \sigma_k )^T$ to the outputs $\bar{p}_{\mathcal{K},k} $. Typically, the pressure is measured in the WTs not the total head, therefore the elevation $\bar{h}_{\mathcal{K}}$ is not added to $\bar{p}_{\mathcal{K},k}$ on the left-hand side in \eqref{recall_output_eq_3}. In the input set, the total consumption can be calculated according to the mass-balance in the whole network such that

\begin{equation}
\label{massbalance_identification}
 \sigma_k = 1^T \hat{d}_k + 1^T \bar{d}_{\mathcal{K},k}.
\end{equation}

 In \eqref{massbalance_identification}, we assume that the flows in the WTs are measured, as the demand flows $\bar{d}_{\mathcal{D},k} $ in the network are not measurable. 

 % Nevertheless, the input and output set together forms the TS $\mathcal{D}_1 = \{u_i ; \tilde{y}_i\}_{i = 1,2, ..., N}$, which can be utilized to carry out the identification on the model.

 \subsection{State equation}
\label{state_eq_identification} 

The state equation is a first-order system of ODEs, which has been formulated on the pressures $\hat{p}$ in the WTs. In order to give a discretization for the approximate solution of the ODEs, Euler-method is used. The Euler-method is the simplest Runge-Kutta method, which provides an acceptable precision for our problem\cite{chicone2006ordinary}. Thus, the discretized state equation yields as follows

\begin{equation}
  \label{WT_matrixform_final_discrete}
\Lambda \frac{1}{T_s} (\hat{p}_{k+1} - \hat{p}_k)  = - (\hat{H}_{\mathcal{C}} - \hat{H}_{\mathcal{T}} \bar{H}^{-1}_{\mathcal{T}}\bar{H}_{\mathcal{C}})  q_{\mathcal{C},k} - \hat{H}_{\mathcal{T}} \bar{H}^{-1}_{\mathcal{T}} K \bar{d}_{\mathcal{K},k} + \hat{H}_{\mathcal{T}} \bar{H}^{-1}_{\mathcal{T}} D v_{\mathcal{D}} \sigma_k.
\end{equation}

\begin{minipage}[t]{0.20\textwidth}
where\\
\hspace*{8mm} $T_s$
\end{minipage}
\begin{minipage}[t]{0.68\textwidth}
\vspace*{2mm}
 is the sampling time.
\end{minipage}
\begin{minipage}[t]{0.10\textwidth}
\vspace*{2mm}
\textcolor{White}{te}$\unit{h}$
\end{minipage} 

Substituting the expression for $q_{\mathcal{C}}$ into \eqref{WT_matrixform_final_discrete}, and expressing the approximation of the derivative term on the left-hand side, the following yields

\vspace{-4mm}
\begin{align}
\label{WT_matrixform_final_discrete1}
\nonumber  \hat{p}_{k+1} - \hat{p}_k  =& T_s \Lambda^{-1} \big(- (\hat{H}_{\mathcal{C}} - \hat{H}_{\mathcal{T}} \bar{H}^{-1}_{\mathcal{T}}\bar{H}_{\mathcal{C}})  q_{\mathcal{C},k}\big ((\hat{p}_k + \hat{h}),\bar{d}_{\mathcal{K},k}, \sigma_k \big) \\ & - \hat{H}_{\mathcal{T}} \bar{H}^{-1}_{\mathcal{T}} K \bar{d}_{\mathcal{K},k} + \hat{H}_{\mathcal{T}} \bar{H}^{-1}_{\mathcal{T}} D v_{\mathcal{D}} \sigma_k \big).
\end{align}
\vspace{-4mm}


The state equation in \eqref{WT_matrixform_final_discrete} describes the relation between the the flows $q_{\mathcal{C},k}$, the total head in the WTs $(\hat{p}_k + \hat{h})$ and the total consumption $\sigma_k$. However, by substituting the $q_{\mathcal{C},k}$ flows with their non-linear expression, the structure of the state equation is not a linear combination of the corresponding signals anymore. Therefore, let us write \eqref{WT_matrixform_final_discrete1} in a form where the non-linear terms are described by a non-linear $\tilde{f}_2(\cdot)$ function with unknown structure. Thus, a reformulated state equation can be given such that

 \begin{equation}
  \label{WT_matrixform_final_discrete2}
     \hat{p}_{k+1} - \hat{p}_k = \tilde{f}_2 \big((\hat{p}_k + \hat{h}),\bar{d}_{\mathcal{K},k}, \sigma_k\big) + \tilde{a}_2 \bar{d}_{\mathcal{K},k} + \tilde{a}_3 \sigma_k,
\end{equation} 


where $\tilde{f}_2$ is a non-linear function, $\tilde{a}_2$ and $\tilde{a}_3$ are parameters of the inlet flows $\bar{d}_{\mathcal{K},k}$ and total consumption $\sigma_k$. 


\section{RBFNN model of the Multi-inlet,Multi-WT system}
\label{RBFNN_model_multi_inlet_multi_WT_sys} 

As a result of substituting the constraints on the flows $q_{\mathcal{C},k}$, the system description has been reduced to a non-linear State Space model with state equation given in \eqref {WT_matrixform_final_discrete2} and output equation in \eqref {recall_output_eq_3}. The complete identification model is summarized in \eqref{identification_model}. 

\begin{equation}
\begin{cases}
  \label{identification_model}
    \hat{p}_{k+1} - \hat{p}_k = \tilde{f}_2 \big((\hat{p}_k + \hat{h}),\bar{d}_{\mathcal{K},k}, \sigma_k\big) + \tilde{a}_2 \bar{d}_{\mathcal{K},k} + \tilde{a}_3 \sigma_k,\\
  \bar{p}_{\mathcal{K},k}  = \tilde{f}_1 \big((\hat{p}_k + \hat{h}),\bar{d}_{\mathcal{K},k}, \sigma_k\big) + \tilde{a}_1 (\hat{p}_k + \hat{h}) - \bar{h}_{\mathcal{K}}.
  \end{cases}
\end{equation} 

The main goal of the system identification is to find a realization of the functions $\tilde{f}_1(\cdot)$ and $\tilde{f}_2(\cdot)$, furthermore to find the parameters $\tilde{a}_1$, $\tilde{a}_2$ and $\tilde{a}_3$. Therefore, the parameters need to be identified, such that the model is able to reproduce the approximate of the state derivatives $(\hat{p}_{k+1} - \hat{p}_k)$ and the outputs $\bar{p}_{\mathcal{K},k}$ from any input set $u_k = ( \hat{p}_k+\hat{h} \ \bar{d}_{\mathcal{K},k} \ \sigma_k )^T$ within the operating regions where we are mapping from.

The identification model shown in \eqref{identification_model} is an abstraction of the first principle model derived in \chapref{system_modelling}. For the constraint on $q_{\mathcal{C},k}$, existence has been implied, however exact structure has not been given. I.e. we know that the relationship exists but an analytical first principle solution for $q_{\mathcal{C},k}$ has not been derived. Therefore, by substituting the implicit expression of the constraint into the state and output equations, some of the insights on the structure of the model are lost. Thus, it is crucial to put a structure on the non-linear functions $\tilde{f}_1(\cdot)$ and $\tilde{f}_2(\cdot)$ in \eqref{identification_model}. 

From a practical point of view, it is beneficial to describe the system by a linear-in-the-parameters model. By restricting ourselves such that the structure of both functions $\tilde{f}_1(\cdot)$ and $\tilde{f}_2(\cdot)$ are linear in the parameters, the parameters of the model can be estimated by simple linear optimization methods, such as Least Squares(LS). For any linear optimization, only the parameters have to enter linearly, as the inputs can depend on any non-linear way on the input data sets. 

By making the restriction on $\tilde{f}_1(\cdot)$ and $\tilde{f}_2(\cdot)$, the two non-linear terms will be approximated by some non-linear functions in both the state and output equations of the model. The tools for carrying out such identification procedure leads to the discussion of Radial Basis Functions(RBFs) and neural networks, which are introduced in \appref{neural_networks}. In \appref{neural_networks}, the main properties of such networks are explained in detail, therefore during the construction of the identification model, these properties are used and applied. 

 \subsection{Output RBFNN}
\label{output_rbfnn}

The output equation described in \eqref{identification_model} is going to be approximated with RBFs in the form as shown in \eqref{output_RBFNNnetwork_approx}.

\begin{subequations}
\label{output_RBFNNnetwork_approx}
  \begin{equation}
\bar{p}_{\mathcal{K}1,k} = \sum_{i = 1}^M w_{\mathcal{K}1,i} \phi_i(u_k) + \sum_{j = 1}^l \tilde{a}_{\mathcal{K}1,j} (\hat{p}_{j,k} + \hat{h}_j) + b_{\mathcal{K}1} - \bar{h}_{\mathcal{K}1},
\end{equation}

\vspace{-2mm}

  \begin{equation}
\bar{p}_{\mathcal{K}2,k} = \sum_{i = 1}^M w_{\mathcal{K}2,i} \phi_i(u_k) + \sum_{j = 1}^l \tilde{a}_{\mathcal{K}2,j} (\hat{p}_{j,k} + \hat{h}_j) + b_{\mathcal{K}2} - \bar{h}_{\mathcal{K}2},
\end{equation}

\end{subequations}


As it was concluded, the output is governed by the non-linear function $\tilde{f}_1$, which maps the inputs $\bar{d}_{\mathcal{K}}$, $\sigma$ and $\hat{h}_t $ to the outputs $\tilde{y}$. This static input-output system can be represented with a RBFNN, shown in \figref{fig:nn_output}.
the interpretation of the Multi-inlet, Multi-WT system in the context of NNs is considered. 

  %NN model of the output eq.
 \begin{figure}[H]
 \centering
 %\includegraphics[width=0.35\textwidth]{report/pictures/missingfigure}
 \input{report/tikz/output_NN1.tex} 
  \vspace{-7mm}
 \caption{NN model of the output equation.}
 \label{fig:nn_output}
 \end{figure}

 \vspace{-3mm}

 In \figref{fig:nn_output}, the first layer consists of the inputs, the hidden layer forms the set of RBFs and, as there are two outputs in the network. The output layer consists of two output neurons which linearly combine the weighted RBFs. Therefore, the output equation written in RBFNN formulation can be given such that 

  \begin{equation}
\label{NN_output_eq1}
\tilde{y}_1 = \sum_{i = 1}^M w_i \phi_i(u) +  w_{0,1},
\end{equation}

where $u = (\bar{d}_{\mathcal{K}} \ \sigma \ \hat{h}_t )^T$. Using vector notation, \eqref{NN_output_eq1} can be rewritten such that

  \begin{equation}
\label{NN_output_vector1}
\tilde{y} = \theta^T_{\tilde{y}} 
          \begin{pmatrix}
           \phi_1(u) \\[1pt]
           \phi_2(u) \\[1pt]
           \vdots \\[1pt]
           \phi_M(u)\\[3pt]
           1 
         \end{pmatrix}
         =
         \theta^T_{\tilde{y}} \chi_{\tilde{y}},
\end{equation}

where $\theta_{\tilde{y}}$ is the regression matrix, including the output weights $w_i$ and the biases $w_0$. Furthermore, $\theta$ has as many columns as the number of inputs. $\chi_{\tilde{y}}$ is called the regressor vector, or in NN context the input vector, consisting of the basis functions and the vector $1 \in \: \mathbb{R}^{c} $, where $c$ is the number of outputs. 

 \subsection{State RBFNN}
\label{state_rbfnn}

The state equation is governed by the non-linear function $\tilde{f}_2$ and furthermore, the states $\hat{p}$ and the elevation of the WTs $\hat{h}$ enter the system linearly. As a consequence of this, the measured data of the states have a strong linear component. In the NN representation this is taken into account such that skip-layer connections are introduced. These extra connections in the NN model are skipping the hidden layer, thereby contribute linearly to the outputs. The illustration of such RBFNN is shown in \figref{fig:nn_state}.

   %NN model of the state eq.
 \begin{figure}[H]
 \centering
 %\includegraphics[width=0.35\textwidth]{report/pictures/missingfigure}
 \input{report/tikz/output_NN.tex} 
 \caption{NN model of the state equation.}
 \label{fig:nn_state}
 \end{figure}

 \vspace{-3mm}

 In \figref{fig:nn_state}, although the input neurons for the skip-layer connections are placed in line with the hidden layer, they are considered as simple inputs, effecting the output layer by the parameters $a_1$ and $a_2$. Nevertheless, the identification is treated as a black-box model, but since insight is given about the network architecture, the NN model can be better matched to the problem by utilizing these skip-layer connections. Furthermore, in \figref{fig:nn_state}, the inputs are all present values and the outputs are the future or predicted values of the states $\hat{p}_{k+1}$. $\hat{h}$ does not have a time step index, as this value is the elevation of WTs, which is time-invariant. 

 Using vector notation, the NN model for the state equation can be given in the form as shown in \eqref{NN_state_vector2}

  \begin{equation}
\label{NN_state_vector2}
\hat{p}_{k+1} = \theta^T_{\hat{p}} 
          \begin{pmatrix}
           \phi_1(u_k) \\[1pt]
           \phi_2(u_k) \\[1pt]
           \vdots \\[1pt]
           \phi_M(u_k)\\[3pt]
           \hat{p}_k \\
           \hat{h}\\
           1 
         \end{pmatrix}
         =
         \theta^T_{\hat{p}} \chi_{\hat{p}},
\end{equation}

where $\theta^T_{\hat{p}}$ is the regression matrix, including the output weights $w_i$, the skip-layer connection weights $a_i$ and the biases $w_0$. The regressor vector $\chi_{\hat{p}}$ consists of the basis functions, the linear inputs $\hat{p}_k$ and $\hat{h}$ and the vector $1 \in \: \mathbb{R}^{l} $, where $l$ is the number of states.




